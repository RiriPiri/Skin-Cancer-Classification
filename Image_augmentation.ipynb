{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Classes detected: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
      "Epoch 1/10 - Loss: 2.2178 - Acc: 0.0342\n",
      "Epoch 2/10 - Loss: 1.8404 - Acc: 0.2360\n",
      "Epoch 3/10 - Loss: 1.6801 - Acc: 0.4720\n",
      "Epoch 4/10 - Loss: 1.5470 - Acc: 0.5031\n",
      "Epoch 5/10 - Loss: 1.3894 - Acc: 0.6118\n",
      "Epoch 6/10 - Loss: 1.2273 - Acc: 0.6894\n",
      "Epoch 7/10 - Loss: 1.0962 - Acc: 0.7205\n",
      "Epoch 8/10 - Loss: 0.9692 - Acc: 0.7733\n",
      "Epoch 9/10 - Loss: 0.8956 - Acc: 0.7795\n",
      "Epoch 10/10 - Loss: 0.7785 - Acc: 0.8665\n",
      "Training complete!\n",
      "Model saved!\n",
      "Predicted: vasc, Confidence: 0.6162\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define dataset paths\n",
    "test_dir = r\"C:\\Black Book Project\\HAM 10000\\HAM10000_split\\test\"\n",
    "valid_dir = r\"C:\\Black Book Project\\HAM 10000\\HAM10000_split\\valid\"\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet expects 224x224 images\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard for ResNet\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=valid_dir, transform=transform)\n",
    "\n",
    "num_classes = len(test_dataset.classes)  # Assuming test & valid have the same class structure\n",
    "print(f\"Classes detected: {test_dataset.classes}\")\n",
    "\n",
    "# Create dataloaders\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model (ResNet-50 with modified classifier)\n",
    "model = models.resnet50(pretrained=True)  # Load pre-trained ResNet-50\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)  # Adjust last layer to match classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, val_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"resnet50_skin_cancer.pth\")\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# Risk Scoring Function\n",
    "def risk_score(image_path, model, class_names):\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probs = torch.nn.functional.softmax(output, dim=1)\n",
    "        score, pred = torch.max(probs, 1)\n",
    "    \n",
    "    return class_names[pred.item()], score.item()\n",
    "\n",
    "# Test risk scoring\n",
    "class_names = test_dataset.classes\n",
    "test_image = r\"C:\\Black Book Project\\HAM 10000\\HAM10000_split\\test\\vasc\\ISIC_0024370.jpg\"\n",
    "# Change to an actual image path\n",
    "predicted_class, confidence = risk_score(test_image, model, class_names)\n",
    "print(f\"Predicted: {predicted_class}, Confidence: {confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available images: ['ISIC_0024370.jpg', 'ISIC_0024475.jpg', 'ISIC_0024662.jpg', 'ISIC_0024747.jpg', 'ISIC_0025197.jpg', 'ISIC_0025244.jpg', 'ISIC_0025250.jpg', 'ISIC_0025452.jpg', 'ISIC_0025578.jpg', 'ISIC_0025596.jpg', 'ISIC_0025599.jpg', 'ISIC_0025606.jpg', 'ISIC_0025612.jpg', 'ISIC_0025628.jpg', 'ISIC_0025677.jpg', 'ISIC_0025680.jpg', 'ISIC_0025707.jpg', 'ISIC_0025873.jpg', 'ISIC_0025924.jpg', 'ISIC_0026092.jpg', 'ISIC_0026336.jpg', 'ISIC_0026467.jpg', 'ISIC_0026490.jpg', 'ISIC_0027159.jpg', 'ISIC_0027210.jpg', 'ISIC_0027665.jpg', 'ISIC_0027672.jpg', 'ISIC_0027856.jpg', 'ISIC_0027888.jpg', 'ISIC_0028431.jpg', 'ISIC_0028714.jpg', 'ISIC_0028885.jpg', 'ISIC_0029404.jpg', 'ISIC_0029439.jpg', 'ISIC_0029448.jpg', 'ISIC_0029608.jpg', 'ISIC_0029742.jpg', 'ISIC_0030104.jpg', 'ISIC_0030606.jpg', 'ISIC_0030770.jpg', 'ISIC_0030882.jpg', 'ISIC_0030956.jpg', 'ISIC_0031093.jpg', 'ISIC_0031103.jpg', 'ISIC_0031201.jpg', 'ISIC_0031217.jpg', 'ISIC_0031346.jpg', 'ISIC_0031719.jpg', 'ISIC_0032076.jpg', 'ISIC_0032240.jpg', 'ISIC_0032538.jpg', 'ISIC_0032692.jpg', 'ISIC_0032745.jpg', 'ISIC_0032866.jpg', 'ISIC_0032867.jpg', 'ISIC_0032890.jpg', 'ISIC_0032919.jpg', 'ISIC_0033123.jpg', 'ISIC_0033135.jpg', 'ISIC_0033158.jpg', 'ISIC_0033230.jpg', 'ISIC_0033254.jpg', 'ISIC_0033450.jpg', 'ISIC_0033458.jpg', 'ISIC_0033608.jpg', 'ISIC_0033749.jpg', 'ISIC_0033762.jpg', 'ISIC_0033817.jpg', 'ISIC_0033844.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "test_vasc_path = r\"C:\\Black Book Project\\HAM 10000\\HAM10000_split\\test\\vasc\"\n",
    "print(\"Available images:\", os.listdir(test_vasc_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
